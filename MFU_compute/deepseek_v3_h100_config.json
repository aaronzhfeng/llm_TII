{
  "_comment": "MFU configuration for DeepSeek V3 on H100 hardware",
  "model_name": "deepseek_v3",
  "hardware": "H100",
  "gpus": 8,
  "precision": "FP8",

  "model_config": {
    "hidden_size": 7168,
    "intermediate_size": 18432,
    "moe_intermediate_size": 2048,
    "num_hidden_layers": 61,
    "num_attention_heads": 128,
    "num_key_value_heads": 128,
    "n_routed_experts": 256,
    "n_shared_experts": 1,
    "num_experts_per_tok": 8,
    "first_k_dense_replace": 3,
    "vocab_size": 129280,
    "tie_word_embeddings": false,
    "max_position_embeddings": 2048,
    "q_lora_rank": 1536,
    "kv_lora_rank": 512,
    "qk_nope_head_dim": 128,
    "qk_rope_head_dim": 64,
    "v_head_dim": 128
  },

  "hardware_specs": {
    "peak_tflops_fp8": 1979,
    "peak_tflops_fp16": 989,
    "peak_tflops_bf16": 989,
    "peak_tflops_fp32": 494,
    "memory_gb": 80,
    "memory_bandwidth_gb_s": 3350,
    "interconnect_bandwidth_gb_s": 900
  },

  "training_config": {
    "batch_size": 16,
    "sequence_length": 2048,
    "gradient_accumulation_steps": 2,
    "mixed_precision": true,
    "optimizer": "AdamW",
    "learning_rate": 1e-4
  },

  "performance_measurements": {
    "_comment": "These should be measured during actual training",
    "tokens_per_second_achieved": 0,
    "throughput_tokens_per_sec_per_gpu": 0,
    "wall_clock_time_per_iteration_ms": 0,
    "peak_memory_used_gb": 0,
    "communication_overhead_percent": 0
  },

  "mfu_targets": {
    "target_mfu_percent": 60,
    "realistic_mfu_percent": 45,
    "minimum_acceptable_mfu_percent": 30
  },

  "references": {
    "paper": "DeepSeek-V3 Technical Report",
    "authors": "DeepSeek AI",
    "year": 2024,
    "url": "https://arxiv.org/abs/2412.19437"
  }
}
